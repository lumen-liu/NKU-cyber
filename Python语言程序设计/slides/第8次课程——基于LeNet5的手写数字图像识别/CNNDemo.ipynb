{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fed197e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1 Train Loss 0.12251093118043958 Train  Accuracy 0.9612206823027718 Teat Loss 0.04421999578473241 Test Accuracy 0.9849683544303798\n",
      "2\n",
      "Epoch 2 Train Loss 0.032869981871618735 Train  Accuracy 0.9896055437100213 Teat Loss 0.024924744118212817 Test Accuracy 0.991495253164557\n",
      "3\n",
      "Epoch 3 Train Loss 0.022034881753505202 Train  Accuracy 0.9934701492537313 Teat Loss 0.032236073035164736 Test Accuracy 0.990506329113924\n",
      "4\n",
      "Epoch 4 Train Loss 0.01611688208611392 Train  Accuracy 0.9948694029850746 Teat Loss 0.030782382982418116 Test Accuracy 0.9903085443037974\n",
      "5\n",
      "Epoch 5 Train Loss 0.012074834617083273 Train  Accuracy 0.996152052238806 Teat Loss 0.03324374901762606 Test Accuracy 0.9890229430379747\n",
      "6\n",
      "Epoch 6 Train Loss 0.009954630497956184 Train  Accuracy 0.9971515191897654 Teat Loss 0.024477557602166817 Test Accuracy 0.9926819620253164\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "#  mnist识别\n",
    "import torch \n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import mnist\n",
    "from torch import  nn\n",
    "from torch.autograd import Variable\n",
    "from torch import  optim\n",
    "from torchvision import transforms\n",
    " \n",
    "# 定义CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "                nn.Conv2d(1,16,kernel_size=3), # 16, 26 ,26\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "                nn.Conv2d(16,32,kernel_size=3),# 32, 24, 24\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2,stride=2)) # 32, 12,12     (24-2) /2 +1\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "                nn.Conv2d(32,64,kernel_size=3), # 64,10,10\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "                nn.Conv2d(64,128,kernel_size=3),  # 128,8,8\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2,stride=2))  # 128, 4,4\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "                nn.Linear(128 * 4 * 4,1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(1024,128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(128,10))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    " \n",
    " \n",
    "# 预处理=>将各种预处理组合在一起\n",
    "data_tf = transforms.Compose(\n",
    "                [transforms.ToTensor(), # 将numpy.ndarray格式数据转换为torch.tensor格式\n",
    "                 transforms.Normalize([0.5],[0.5])]) # 归一化处理，把0~255的灰度像素值数据归一化为均值为0.5、标准差为0.5的数据\n",
    "  \n",
    "# 使用内置函数下载mnist数据集\n",
    "train_set = mnist.MNIST('./data',train=True,transform=data_tf,download=True)\n",
    "test_set = mnist.MNIST('./data',train=False,transform=data_tf,download=True)\n",
    " \n",
    "train_data = DataLoader(train_set,batch_size=64,shuffle=True)\n",
    "test_data = DataLoader(test_set,batch_size=128,shuffle=False)\n",
    " \n",
    "net = CNN()\n",
    "criterion = nn.CrossEntropyLoss() # 使用交叉熵损失\n",
    "optimizer = optim.SGD(net.parameters(),1e-1) # 随机梯度下降，学习率为0.1\n",
    " \n",
    "nums_epoch = 20\n",
    " \n",
    "# 开始训练\n",
    "losses =[]\n",
    "acces = []\n",
    "eval_losses = []\n",
    "eval_acces = []\n",
    " \n",
    "for epoch in range(nums_epoch):\n",
    "    print(epoch+1)\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    net = net.train()\n",
    "    for img , label in train_data:\n",
    "        #img = img.reshape(img.size(0),-1) \n",
    "        img = Variable(img) # 转换成PyTorch的一个变量（新版本不需要）\n",
    "        label = Variable(label)\n",
    "        \n",
    "        # 前向传播\n",
    "        out = net(img)\n",
    "        loss = criterion(out,label)\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad() # 每次将梯度重置为0\n",
    "        loss.backward() # 反向调整参数\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 记录误差\n",
    "        train_loss += loss.item()\n",
    "        # 计算分类的准确率\n",
    "        _,pred = out.max(1) # 取评分最高的结果作为所分的类别\n",
    "        num_correct = (pred == label).sum().item()\n",
    "        acc = num_correct / img.shape[0]\n",
    "       \n",
    "        train_acc += acc\n",
    "        \n",
    "    losses.append(train_loss / len(train_data))\n",
    "    acces.append(train_acc / len(train_data))\n",
    "    \n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    # 测试集不训练\n",
    "    for img , label in test_data:\n",
    "        #img = img.reshape(img.size(0),-1)\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "        \n",
    "        out = net(img)\n",
    "        \n",
    "        loss = criterion(out,label)\n",
    "        \n",
    "        # 记录误差\n",
    "        eval_loss += loss.item()\n",
    "        \n",
    "        _ , pred = out.max(1)\n",
    "        num_correct = (pred==label).sum().item()\n",
    "        acc = num_correct / img.shape[0]\n",
    "        \n",
    "        eval_acc += acc\n",
    "    eval_losses.append(eval_loss / len(test_data))\n",
    "    eval_acces.append(eval_acc / len(test_data))\n",
    "    \n",
    "    print('Epoch {} Train Loss {} Train  Accuracy {} Teat Loss {} Test Accuracy {}'.format(\n",
    "        epoch+1, train_loss / len(train_data),train_acc / len(train_data), eval_loss / len(test_data), eval_acc / len(test_data)))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d37ae04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4c/d9/713853e06954bb657607d1e59d29e5896e1933e5d7fb50847a5730ad7325/torch-1.13.0-cp39-cp39-win_amd64.whl (167.2 MB)\n",
      "Collecting torchvision\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a7/f3/aaac29c2cdb84b0be1302aa17a68a7c39b05d9bca810d144e42c7131fb0d/torchvision-0.14.0-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "Collecting torchaudio\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/43/f9/629822b68e9513cd5e3255b632a2dc1216a078e9edde30a76b562108bc26/torchaudio-0.13.0-cp39-cp39-win_amd64.whl (2.1 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.1.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-1.13.0 torchaudio-0.13.0 torchvision-0.14.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio -i https://pypi.tuna.tsinghua.edu.cn/simple/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56b9812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "271aaf9a14ca8aef692edd0e58d89184235237d981934b751bc9762a3149e378"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
